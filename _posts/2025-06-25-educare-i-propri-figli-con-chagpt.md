---
layout: default_post
title:  "Educare i propri figli con ChatGPT.. "
date:   2025-06-25
description: ""
url_image: ""
tag_name: "blog"
---

Per far comprendere il motivo per cui nutro delle profonde preoccupazioni sul futuro dell'informazione ai tempi dell'intelligenza artificiale,  vorrei spiegare il concetto di astrazione in informatica. 

Cosa significa astrarre? 

L'astrazione, è quella pratica secondo cui si sceglie di mettere da parte la complessità di una cosa sostituendola con simboli e concetti molto più semplici, rendendola a disposizione per il loro utilizzo, anche a chi non ne sa niente.  

Per gli informatici addormentati o alle prime armi ecco cosa intendo: 

```
def calcola_area_quadrato(lato):
    return lato * lato

print(calcola_area_quadrato(2))

```

L'esempio sopra è molto semplice, si dichiara una funzione per il calcolo dell'area di un quadrato.

Noi potremmo scegliere di non sapere come si calcoli l'area del quadrato, eppure la funzione "calcola_area_quadrato()" è a nostra disposizione per la risoluzione del problema. 

Io scelgo di mettere una funzione riutilizzabile così che non debba fare lo stesso calcolo più volte ma utilizzando una semplicissima funzione.

Ogni teorema, ogni scoperta scoperta scientifica, si basa su questi "strati" e costruendoci su si è riusciti a risolvere grandi problemi richiedendo meno sforzo di quanto necessario. 

Consapevolmente scegli di mettere da parte la conoscenza di com'è fatto quello strumento per permetterti di poterlo utilizzare senza che tu debba ripetutamente sbattere la testa contro il muro o piangere sui libri. 

Per chi non passa la vita a smadonnare sul codice e  non avesse ancora capito cosa di cosa io stia parlando avrà le idee più chiare: l'applicazione di questo concetto è ovunque nella vita di tutti i giorni. 

In questo momento stai guardando questo post in un dispositivo di cui non hai la più pallida idea di come sia stato costruito, eppure lo utilizzi tranquillamente senza farti troppi problemi. 

Certo essere più consapevole di come vengono fatte le cose ti aiuterebbe in un utilizzo più consapevole e per darti una marcia in più, ma non è necessario

Semplicemente scegliamo di rimanere ignoranti perchè non è affar nostro e avremmo molto altro da fare che deprimerci sulla costruzione da zero di un computer (per non parlare della parte software).

Si potrebbero fare migliaia di esempi, dai più pratici ai più astratti. Siate coscienti del fatto che ogni giorno noi utilizziamo gli oggetti attorno a noi ignorandone il come sono fatti, barattando la nostra conoscenza con il tempo. 

Il problema dell'astrazione è la **dipendenza** , la minima assenza di qualcosa da cui dipendiamo ci crea enormi problemi. 

Di fatto è come funziona il mondo, noi non possiamo sapere tutto, dipendiamo da altri che hanno competenze diverse, collaborando costruiamo cose che possano semplificarci la vita. 

Perchè quindi mi sono messo a parlare di astrazione? 

Perchè potremmo replicare tale concetto al modo in cui ci formiamo le nostre opinioni, al cosa decidere di credere e al modo in cui noi vediamo il mondo. 

Ognuno si informa, nel bene o nel male, da fonti, dati, opinioni prese e costruite da altre persone, di cui più o meno siamo in grado di verificarne la veridicità. 

Nel ricavare informazioni, noi ci "fidiamo", sperando che chiunque crei quelle informazioni abbia lo scopo di fare informazione, di raccontare la "realtà".

L'astrazione è livello umano è un atto di "fiducia": si costruisce sopra supponendo che le costruzioni logiche dietro siano corrette, e ci costruiamo la nostra realtà. 

Noi astraiamo, supponiamo che le cose siano prese correttamente, nel cercare di creare una nostra opinione ci capita molto spesso che le fonti da cui ci informiamo ci "vomitino" la loro, prima ancora di farcene una.  

E' un problema che è sempre esistito. Ma qui, viste le proporzioni di questo tipo di innovazioni, è un rischio molto più elevato.

Potremmo mitigare il problema, se siamo furbi potremmo incrociare le fonti e dare opinioni in base a ricerche approfondite, ma chi ha tempo? 

Quanti hanno l'effettiva consapevolezza su cosa basano le proprie opinioni? E chi è così umile da riconoscere di non avere sempre i mezzi con cui interpretare la realtà in maniera critica?

Vogliamo veramente far finta di niente e chiudere gli occhi davanti alle conseguenze nell'affidare quali informazioni farci fornire a terzi? 

Immaginatevi vedere generazioni intere che dimenticano l'utilizzo di un motore di ricerca, di leggere un libro, un articolo..  e affidare le loro intera conoscenza del mondo a ChatGPT. 

Gli LLM permettono di aggiungere un ulteriore livello di astrazione rispetto ai motori di ricerca: di fatto non ci preoccupiamo più di quali siano i siti da cui informarsi, ci viene già dato il risultato alla nostra domanda. 

Non dovremmo più sbatterci nel cercare nei vari siti le informazioni utili per rispondere al problema. Questo con tutte le conseguenze del caso. 

Di sto passo il prossimo step sarà farci iniettare le informazioni direttamente nel cervello, non dovremmo più sforzarci a leggere.

Poi, chi ci garantisce che la fonte dica sempre il vero? 

E si, gli LLM possono fare propaganda politica, Deepseek ne è un grande esempio: dopo l'uscita è stato immediatamente censurato per fare in modo che le risposte fossero in linea con la propaganda del Partito Comunista Cinese. 

Altro esempio ancora? Ecco alcuni post di Elon Musk su X:

<div class="text-center px-2">
<a href="https://x.com/elonmusk/status/1936333964693885089" target="_blank"><img class="rounded img-fluid my-2" src="/assets/images/x_musk_1.png"></a>

<a href="https://x.com/elonmusk/status/1936493967320953090" target="_blank"><img class="rounded img-fluid my-2" src="/assets/images/x_musk_2.png"></a>
</div>

Chi crea questi modelli, ha il potere (magari non è nemmeno nel loro interesse, spezziamo una lancia a favore) di creare una narrazione che può far comodo ai propri interessi, e introdurla ai suoi utilizzatori. E ne è pienamente consapevole. 

Per non parlare anche di ipotetici attacchi informatici che possono avere lo scopo di influenzare le risposte di questi modelli, creando ulteriore disinformazione. 

Queste situazioni sollevano questioni importanti: chi ha il diritto morale di definire cosa sia reale o no, giusto e sbagliato?

A volte scegliere quali tecnologie usare, non è un semplice scelta di un mezzo per arrivare a un fine, ma è una scelta più o meno consapevole a una certa visione del mondo.  

Con questo post non sto dicendo che per verificare le nostre opinioni dovremmo reinventare la ruota, che dovremmo prendere ogni singolo dato a mano e vivere ogni singola cosa per poterci credere. 

Ma penso sia vitale sottolineare il come ci sia una scarsa consapevolezza delle persone sulle implicazioni nell'affidarsi a enormi mezzi di informazione come i modelli di intelligenza artificiale.                                                                                           

